import pandas as pd
from xgboost import XGBClassifier
import joblib
import os




def train_model(data_path=r"C:\Users\btk02\OneDrive\Desktop\Yeni klasÃ¶r\data\dataset.csv",
                save_path="data/model.pkl"):
    try:
        # Veri setini oku
        print("ğŸ“¥ Veri okunuyor...")
        df = pd.read_csv(data_path)

        if df.empty:
            raise ValueError("â—ï¸dataset.csv dosyasÄ± boÅŸ. EÄŸitim yapÄ±lamaz.")

        print(f"âœ… {len(df)} satÄ±r veri yÃ¼klendi.")

        # Feature engineering
        df["Kan BasÄ±ncÄ± FarkÄ±"] = df["Sistolik"] - df["Diyastolik"]
        df["Kan BasÄ±ncÄ± OranÄ±"] = df["Sistolik"] / df["Diyastolik"]
        df["AteÅŸ DeÄŸiÅŸim HÄ±zÄ±"] = (df["AteÅŸ"] - df["AteÅŸ"].shift(1)).fillna(0)

        X = df[["YaÅŸ", "NabÄ±z", "Sistolik", "Diyastolik",
                "Kan BasÄ±ncÄ± FarkÄ±", "Kan BasÄ±ncÄ± OranÄ±", "AteÅŸ DeÄŸiÅŸim HÄ±zÄ±"]]
        y = df["Hasta_mÄ±"]

        # Model eÄŸit
        print("ğŸ¤– Model eÄŸitiliyor...")
        model = XGBClassifier(n_estimators=200, max_depth=10, learning_rate=0.1)
        model.fit(X, y)

        # KayÄ±t klasÃ¶rÃ¼ oluÅŸturulmazsa hata almasÄ±n
        os.makedirs(os.path.dirname(save_path), exist_ok=True)

        # Modeli kaydet
        joblib.dump(model, save_path)
        print(f"âœ… Model baÅŸarÄ±yla kaydedildi: {os.path.abspath(save_path)}")

    except FileNotFoundError:
        print(f"âŒ dataset.csv bulunamadÄ±: {data_path}")

    except pd.errors.EmptyDataError:
        print("âŒ dataset.csv dosyasÄ± boÅŸ veya hatalÄ±.")

    except Exception as e:
        print(f"ğŸš¨ EÄŸitim sÄ±rasÄ±nda beklenmeyen bir hata oluÅŸtu: {str(e)}")

if __name__ == "__main__":
    train_model()        